---
标题: "阿里分享RAG技术四大核心挑战及解决方案"
链接: "https://x.com/hongming731/status/1910337789130052083"
作者: "[[X (formerly Twitter)]]"
创建时间: "2025-04-11T21:18:48+08:00"
摘要: "阿里分享了RAG技术在客服和内部助手应用中的四大核心挑战及解法，涵盖数据质量、精准检索、抑制幻觉和精细化评估。"
tags:
  - "AI/增强技术/RAG"
  - "AI/增强技术/知识图谱"
  - "AI/大模型"
  - "AI/方法论/效率"
  - "类型/技术"
---


《RAG 技术演进的四大核心命题》

分享一篇阿里关于 RAG 的干货，他们用 RAG 优化客服和内部助手，主要是为了解决大模型瞎说（幻觉）和知识老旧的问题。

文章总结了他们搞 RAG 碰到的四大核心挑战和对应的解法，这些问题比较有共性：

挑战一：数据质量与关系挖掘

痛点：知识库来源杂（文档、语雀、笔记），质量差，模型“垃圾进垃圾出”。光有文本不够，还得理解知识点之间的关联。

解法：不只是切分文档，而是构建知识图谱 (Graph)，把零散信息和它们之间的关系都串起来，让模型能理解得更深。

挑战二：复杂问题的精准检索

痛点：简单的文本/向量相似度不够用，很多问题需要结合多个来源、甚至多步推理才能找到答案。异构数据检索困难。

解法：搞了智能检索，先用大模型理解和拆解复杂问题，改写得更适合搜索。然后用混合检索（文本+向量+图谱）一起上，提高召回率和精度。不行还能迭代式检索，像 Agent 一样自动调整策略再搜几次。

挑战三：抑制幻觉，提升生成可信度

痛点：就算搜到了相关信息，大模型还是可能瞎编、忽略关键信息或用不好搜到的内容。

解法：核心是过滤掉“虽然相关但不解决问题”的检索结果。他们搞了个 RAR (Retrieval-Augmented Relevance)，用另一个模型先判断搜来的内容是不是真有用、真能回答问题，再喂给生成模型，大大减少幻觉。

挑战四：精细化评估与问题定位

痛点：传统指标（如准确率）太粗了，告诉你结果不好，但说不清问题到底出在哪一环（是没搜到？还是搜到了但没用好？）。

解法：自建了一套超详细的评估体系 RAG Diagnoser。它能把模型的回答拆解成一个个“原子事实”，然后逐个对比标准答案，精准定位是检索、改写还是生成环节拉胯了，方便针对性优化。

总的来说，阿里这套思路就是系统性地从数据、检索、生成控制、评估这四个核心方面死磕 RAG 的效果和可靠性，干货挺多的，希望能给你点启发！

![Image](https://pbs.twimg.com/media/GoLh9J4bsAA79Pp?format=jpg&name=large) ![Image](https://pbs.twimg.com/media/GoLh_N2b0AAG8b9?format=jpg&name=large) ![Image](https://pbs.twimg.com/media/GoLiCS2bkAA-woa?format=jpg&name=large) ![Image](https://pbs.twimg.com/media/GoLiFxLbQAAL9no?format=jpg&name=large)

---
