---
标题: "Thread by @idoubicc"
链接: "https://x.com/idoubicc/status/1917397672119656488"
作者: "[[@idoubicc]]"
创建时间: "2025-05-02T17:26:16+08:00"
摘要: "文章澄清了关于MCP协议的三个常见误区，强调MCP协议不需要大模型支持，不依赖Function Calling机制，且大模型不可能原生支持MCP。"
tags:
  - "AI"
  - "大模型"
  - "MCP协议"
  - "Function Calling"
  - "效率"
---
**idoubi** @idoubicc [2025-04-30](https://x.com/idoubicc/status/1917397672119656488)

关于 MCP 的几个理解误区：

1\. 误区 1：MCP 协议需要大模型支持

MCP 全称模型上下文协议，是为了在用户与大模型对话过程中，补充上下文信息给大模型，让大模型更准确的回答用户提问而设计的。

在 MCP 出来之前，有多种方式可以实现上下文信息的补充，比如：

\- 记忆存储。把对话过程的历史消息存储下来，每次新提问，带上历史消息一起发送给大模型

\- RAG。在让大模型回答问题之前，先从本地知识库或者互联网上检索信息，作为上下文补充给大模型

\- Function Calling。传递一堆工具给大模型挑选，根据大模型的返回参数，调用工具，用工具返回的结果作为上下文补充给大模型

理解了给大模型补充上下文的原理，就可以知道，MCP 的本质，是指导应用层，如何更好的补充上下文信息给大模型。

模型收到回复提问请求时，MCP 工作已经完成了。

结论：MCP 协议不需要大模型支持，哪怕你使用古老的 gpt-2 作为问答模型，依然可以使用 MCP 协议补充上下文信息。

2\. 误区 2：只有支持 Function Calling 的模型才支持 MCP 协议

聊 MCP 协议，必须要理解 Function Calling 机制。

\- Function Calling 是一种交互范式。

基本流程是应用层传递一堆工具给大模型，大模型意图识别，做一次 Pick Tool 操作，返回应该调用的工具名称和调用参数，再由应用层发起 Call Tool 操作，拿到结果重新给到大模型回答。

Function Calling 这套机制下有三个角色：应用、资源方、大模型。

两个核心步骤：Pick Tool 和 Call Tool。

Pick Tool 需要大模型推理，Call Tool 需要应用与资源方交互。

\- MCP 协议是一套交互标准。可以理解为 MCP 是对 Function Calling 机制的包装与升级。

MCP 协议定义了三个角色：主机、客户端、服务器。

跟 Function Calling 机制相比，MCP 协议相当于是把 客户端-服务器 作为一个黑盒。

整体视角看，MCP 协议有四个角色：主机应用、黑盒（客户端-服务器）、资源方、大模型

主机把请求给到客户端，客户端请求服务器，服务器对接资源方，主机最终得到黑盒返回的结果，作为补充上下文给到大模型回答。

Function Calling 是应用直接对接资源，MCP 是应用通过黑盒对接资源，对接更加标准化，资源接入成本更低。

Function Calling 是应用直接定义一堆工具，MCP 是应用从 MCP 服务器获取定义好的工具，应用无需重复编码。

涉及到工具调用的环节，MCP 与 Function Calling 的交互形式一致。都依赖大模型的 Pick Tool 能力。

所谓的大模型支持 Function Calling，是指大模型在 Pick Tool 环节，有更好的理解和推理能力，最终能返回更加准确的 Tool 和参数。

不支持 Function Calling 的模型，依然可以通过提示词工程实现 Pick Tool。只不过准确度不如支持 Function Calling 的模型。

结论：不支持 Function Calling 的模型，依然可以使用 MCP 协议补充上下文信息。

3\. 误区 3：大模型原生支持 MCP 协议

所谓的大模型原生支持 MCP 协议，正确的理解应该是大模型内化了 MCP 协议的定义，并且内置集成了大量基于 MCP 协议定义的工具。

当接到用户提问时，应用即使不给大模型传递任何工具，大模型依然可以基于内化的工具列表进行推理，返回应该调用的工具名称和调用参数给应用。

事实上，互联网上的资源是千差万别的，意味着对接资源的 MCP 服务器及其内部的工具是海量的，不可枚举的。

另一个关键点是，某些资源是私有的，需要用户鉴权的，大模型训练时不可能内化用户的鉴权凭证。

从这个角度来讲，大模型内化 MCP 协议下的海量工具，不现实也不可能。

某些模型厂商，也许是为了蹭 MCP 的热度，某些自媒体，也许是对 MCP 协议理解不到位，宣称某大模型原生支持 MCP 协议。

其实要表达的意思，也许只是，在随大模型一起发布的某个 agent 框架里面，加上了对 MCP 协议的支持。

结论：大模型原生支持 MCP 协议，这种说法是不专业的。大模型现阶段不可能原生支持 MCP。

本人认知有限，也许会有理解偏颇之处。欢迎补充交流。🙂